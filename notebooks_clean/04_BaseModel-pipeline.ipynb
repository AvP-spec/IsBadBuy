{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from avp_pckg.DataFrame import AvPdataFrame \n",
    "from avp_pckg.avp_model_selection import cross_validate_pipe\n",
    "from avp_pckg.avp_model_selection import plot_scores, wheels_type_split, print_scores\n",
    "from avp_pckg.avp_model_selection import PrepareColsBase, PrepareColsTEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score # accuracy_score, recall_score, precision_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of a base models with whole dataset\n",
    "- decision tree \n",
    "- random forest\n",
    "- logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data as train and test sets.\n",
    "Data types of the coulumns needs to be checked. In current dataset 'WheelTypeID' column have a mixed datatype and should be handled separatrly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "not solved: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv('data\\\\features_train.csv', parse_dates=['PurchDate'], index_col=0)\n",
    "features_test = pd.read_csv('data\\\\features_test.csv', parse_dates=['PurchDate'], index_col=0)\n",
    "\n",
    "target_train = pd.read_csv('data\\\\target_train.csv', index_col=0)\n",
    "target_test = pd.read_csv('data\\\\target_test.csv', index_col=0)\n",
    "\n",
    "# features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(str)\n",
    "features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(float)\n",
    "features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(str)\n",
    "print(features_train.shape, target_train.shape)\n",
    "features_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Select categorical and numerical columns\n",
    "For the base model all columns are used (exept 'PurchDate': droped in pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = ['Auction', 'VehicleAge', 'Make', 'Model', 'Trim', 'SubModel', 'WheelType', 'BYRNO', 'VNZIP1', # cols to use\n",
    "            'Nationality', 'IsOnlineSale', 'Transmission', 'Color', 'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'Size', 'VNST', 'VehYear', 'WheelTypeID'] # cols to drop\n",
    "\n",
    "cols_num = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\n",
    "            'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "            'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "            'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', \n",
    "            'VehOdo', 'VehBCost', 'WarrantyCost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tree-model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time= 34 s \n",
    "param_name ='max_depth'\n",
    "param_range = [3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name='max_depth tree')\n",
    "print_scores(score_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest-model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time= 2m 12s \n",
    "param_name ='max_depth'\n",
    "param_range = [3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='forest', # 'forest', 'logistic', 'tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name=param_name)\n",
    "print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regresion - model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name ='C'\n",
    "param_range = [0.001, 0.002, 0.004, 0.01, 0.02, 0.04, 0.1, 1, 10,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='logistic', # 'forest', 'logistic', 'tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name=param_name, xlog=True)\n",
    "print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | support |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |- |- | - | - |\n",
    "| Forest | depth=10 |0.382 | - | - |- | - |\n",
    "| LogReg | C=0.01 | 0.375 | - | - |- | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Tree model #########################################################\n",
    "pipe_tree = Pipeline(steps=[\n",
    "('base', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', DecisionTreeClassifier(class_weight='balanced', random_state=42, max_depth=4))\n",
    "])\n",
    "\n",
    "pipe_tree.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "\n",
    "pred_tree = pipe_tree.predict(features_test)\n",
    "df_pred_tree = pd.DataFrame(pred_tree, index=features_test.index)\n",
    "df_pred_tree.columns = ['tree']\n",
    "\n",
    "report = classification_report(target_test, pred_tree)\n",
    "print('tree report: \\n', report)\n",
    "print('tree pred.sum():', pred_tree.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Forest model #########################################################\n",
    "pipe_forest = Pipeline(steps=[\n",
    "('base', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', RandomForestClassifier(class_weight='balanced', random_state=42, max_depth=10))\n",
    "])\n",
    "\n",
    "pipe_forest.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "pred_forest = pipe_forest.predict(features_test)\n",
    "df_pred_forest = pd.DataFrame(pred_forest, index=features_test.index)\n",
    "df_pred_forest.columns = ['forest']\n",
    "\n",
    "\n",
    "report = classification_report(target_test, pred_forest)\n",
    "print('forest report: \\n', report)\n",
    "print('forest pred.sum():', pred_forest.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_reg = Pipeline(steps=[\n",
    "('preprocessing', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', LogisticRegression(class_weight='balanced', random_state=42, C=0.01))\n",
    "])\n",
    "\n",
    "pipe_reg.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "pred_reg = pipe_reg.predict(features_test)\n",
    "df_pred_reg = pd.DataFrame(pred_reg, index=features_test.index)\n",
    "df_pred_reg.columns = ['logistic']\n",
    "\n",
    "report = classification_report(target_test, pred_reg)\n",
    "print('regression report: \\n', report)\n",
    "print('logistig pred.sum():', pred_reg.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |0.30 |0.49  |0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 |0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  |0.30 | 5548 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([df_pred_tree, df_pred_forest, df_pred_reg], axis=1)\n",
    "df_pred.loc[:, 'sum'] = df_pred['tree'] + df_pred['forest'] + df_pred['logistic']\n",
    "df_pred.loc[:, 'result1'] = round((df_pred['sum']+1)/3).astype(int)\n",
    "df_pred.loc[:, 'result2'] = round((df_pred['sum']+0)/3).astype(int)\n",
    "df_pred.loc[:, 'result3'] = round((df_pred['sum']-1)/3).astype(int)\n",
    "\n",
    "display(df_pred.head())\n",
    "print(df_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(target_test, df_pred['result3'])\n",
    "print('result3 report: \\n', report)\n",
    "\n",
    "report = classification_report(target_test, df_pred['result2'])\n",
    "print('result2: \\n', report)\n",
    "\n",
    "report = classification_report(target_test, df_pred['result1'])\n",
    "print('result1: \\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |0.30 |0.49  |0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 |0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  |0.30 | 5548 |\n",
    "|Ensamble prec| - |- |0.32|0.48|0.38|1909|\n",
    "|Ensamble recall| - |- |0.18|0.81|0.30|5752|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation original data set\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 | 0.30 | 0.49  | 0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 | 0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  | 0.30 | 5548 |\n",
    "|Ensamble| - |- |0.32 | 0.48 | 0.38 | 1909 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
