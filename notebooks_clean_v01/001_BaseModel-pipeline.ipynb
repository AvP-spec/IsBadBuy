{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of a base models with whole dataset\n",
    "- decision tree \n",
    "- random forest\n",
    "- logistic regression\n",
    "\n",
    "Public Score 0.14431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add current directory to system path for relative import of the castom pakage: avp_pckg\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## geting one level above current path \n",
    "path_absolute = os.path.dirname(os.getcwd()) \n",
    "\n",
    "if path_absolute in sys.path:\n",
    "    print(f\"alrady in sys.path: {path_absolute}\")\n",
    "else:\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))\n",
    "    print(f\"added to sys.path: {path_absolute}\"  )\n",
    "\n",
    "## for debagging     \n",
    "# for p in sys.path:\n",
    "#     print(p)\n",
    "    \n",
    "## check import from avp_pckg\n",
    "from avp_pckg.DataFrame import AvPdataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipelines\n",
    "# from sklearn.impute import SimpleImputer\n",
    "# from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report  # f1_score,  accuracy_score, recall_score, precision_score\n",
    "\n",
    "## castom package \n",
    "from avp_pckg.DataFrame import AvPdataFrame \n",
    "from avp_pckg.avp_model_selection import cross_validate_pipe \n",
    "from avp_pckg.avp_model_selection import plot_scores, print_scores\n",
    "from avp_pckg.avp_model_selection import PrepareColsBase # PrepareColsTEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## switch on if modifications in avp_pckg are requared for auto-reload of the pakages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data as train and test sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data types of the coulumns needs to be checked. In current dataset 'WheelTypeID' column have a mixed datatype and should be handled separatrly \n",
    "\n",
    "not solved: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv(path_absolute + '\\\\data\\\\features_train.csv', parse_dates=['PurchDate'], index_col=0)\n",
    "features_test = pd.read_csv(path_absolute + '\\\\data\\\\features_test.csv', parse_dates=['PurchDate'], index_col=0)\n",
    "\n",
    "target_train = pd.read_csv(path_absolute + '\\\\data\\\\target_train.csv', index_col=0)\n",
    "target_test = pd.read_csv(path_absolute + '\\\\data\\\\target_test.csv', index_col=0)\n",
    "\n",
    "# features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(str)\n",
    "features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(float)\n",
    "features_train.loc[:, 'WheelTypeID'] = features_train['WheelTypeID'].astype(str)\n",
    "print(features_train.shape, target_train.shape)\n",
    "features_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Select categorical and numerical columns\n",
    "For the base model all columns are used (exept 'PurchDate': droped in pipeline) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_cat = ['Auction', 'VehicleAge', 'Make', 'Model', 'Trim', 'SubModel', 'WheelType', 'BYRNO', 'VNZIP1', # cols to use\n",
    "            'Nationality', 'IsOnlineSale', 'Transmission', 'Color', 'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'Size', 'VNST', 'VehYear', 'WheelTypeID'] # cols to drop\n",
    "\n",
    "cols_num = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\n",
    "            'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "            'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "            'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', \n",
    "            'VehOdo', 'VehBCost', 'WarrantyCost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tree-model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time= 34 s \n",
    "param_name ='max_depth'\n",
    "param_range = [3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name='max_depth tree')\n",
    "print_scores(score_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest-model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time= 2m 12s \n",
    "param_name ='max_depth'\n",
    "param_range = [3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='forest', # 'forest', 'logistic', 'tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name=param_name)\n",
    "print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regresion - model with whole dataset\n",
    "cross-validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution time= 15s \n",
    "param_name ='C'\n",
    "param_range = [0.001, 0.002, 0.004, 0.01, 0.02, 0.04, 0.1, 1, 10,]\n",
    "score_dict = cross_validate_pipe(X=features_train,\n",
    "                                y=target_train,\n",
    "                                cols_cat=cols_cat,\n",
    "                                cols_num=cols_num,\n",
    "                                param_name=param_name,\n",
    "                                param_range= param_range,\n",
    "                                cv=5, \n",
    "                                max_cat=25,\n",
    "                                estimator_name='logistic', # 'forest', 'logistic', 'tree',\n",
    "                                n_jobs=-1,\n",
    "                                )\n",
    "\n",
    "plot_scores(score_dict, param_name=param_name, xlog=True)\n",
    "print_scores(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | support |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |- |- | - | - |\n",
    "| Forest | depth=10 |0.382 | - | - |- | - |\n",
    "| LogReg | C=0.01 | 0.375 | - | - |- | - |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Tree model #########################################################\n",
    "pipe_tree = Pipeline(steps=[\n",
    "('base', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', DecisionTreeClassifier(class_weight='balanced', random_state=42, max_depth=4))\n",
    "])\n",
    "\n",
    "pipe_tree.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "\n",
    "pred_tree = pipe_tree.predict(features_test)\n",
    "df_pred_tree = pd.DataFrame(pred_tree, index=features_test.index)\n",
    "df_pred_tree.columns = ['tree']\n",
    "\n",
    "report = classification_report(target_test, pred_tree)\n",
    "print('tree report: \\n', report)\n",
    "print('tree pred.sum():', pred_tree.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Forest model #########################################################\n",
    "pipe_forest = Pipeline(steps=[\n",
    "('base', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', RandomForestClassifier(class_weight='balanced', random_state=42, max_depth=10))\n",
    "])\n",
    "\n",
    "pipe_forest.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "pred_forest = pipe_forest.predict(features_test)\n",
    "df_pred_forest = pd.DataFrame(pred_forest, index=features_test.index)\n",
    "df_pred_forest.columns = ['forest']\n",
    "\n",
    "\n",
    "report = classification_report(target_test, pred_forest)\n",
    "print('forest report: \\n', report)\n",
    "print('forest pred.sum():', pred_forest.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic #########################################################\n",
    "pipe_reg = Pipeline(steps=[\n",
    "('preprocessing', PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()),\n",
    "('model', LogisticRegression(class_weight='balanced', random_state=42, C=0.01))\n",
    "])\n",
    "\n",
    "pipe_reg.fit(features_train, target_train['IsBadBuy'].to_numpy())\n",
    "pred_reg = pipe_reg.predict(features_test)\n",
    "df_pred_reg = pd.DataFrame(pred_reg, index=features_test.index)\n",
    "df_pred_reg.columns = ['logistic']\n",
    "\n",
    "report = classification_report(target_test, pred_reg)\n",
    "print('regression report: \\n', report)\n",
    "print('logistig pred.sum():', pred_reg.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |0.30 |0.49  |0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 |0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  |0.30 | 5548 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([df_pred_tree, df_pred_forest, df_pred_reg], axis=1)\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([df_pred_tree, df_pred_forest, df_pred_reg], axis=1)\n",
    "df_pred.loc[:, 'sum'] = df_pred['tree'] + df_pred['forest'] + df_pred['logistic']\n",
    "df_pred.loc[:, 'result1'] = round((df_pred['sum']+1)/3).astype(int)\n",
    "df_pred.loc[:, 'result2'] = round((df_pred['sum']+0)/3).astype(int)\n",
    "df_pred.loc[:, 'result3'] = round((df_pred['sum']-1)/3).astype(int)\n",
    "\n",
    "display(df_pred.head())\n",
    "print(df_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(target_test, df_pred['result3'])\n",
    "print('result3 report: \\n', report)\n",
    "\n",
    "report = classification_report(target_test, df_pred['result2'])\n",
    "print('result2: \\n', report)\n",
    "\n",
    "report = classification_report(target_test, df_pred['result1'])\n",
    "print('result1: \\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 |0.30 |0.49  |0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 |0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  |0.30 | 5548 |\n",
    "|Ensamble prec| - |- |0.32|0.48|0.38|1909|\n",
    "|Ensamble recall| - |- |0.18|0.81|0.30|5752|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation original data set\n",
    "| model | parameter | f1_cv | precision  | recall | f1-score | pred.sum() |\n",
    "|---|---|---|---|---|---|---|\n",
    "| Tree | depth=4 | 0.376 | 0.30 | 0.49  | 0.37 | 2162 |\n",
    "| Forest | depth=10 |0.382 | 0.24 |  0.60 | 0.35 | 3143 |\n",
    "| LogReg | C=0.01 | 0.375 | 0.19  | 0.80  | 0.30 | 5548 |\n",
    "|Ensamble| - |- |0.32 | 0.48 | 0.38 | 1909 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "the best results in f1 score were achieved by unanimous vote of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check function for unanimity vote\n",
    "from avp_pckg.small_functions import unanimity\n",
    "pred_lst = [df_pred_tree, df_pred_forest, df_pred_reg]\n",
    "result = unanimity(pred_lst)\n",
    "\n",
    "report = classification_report(target_test, result)\n",
    "print('result report: \\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare workflow for prediction of aim data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original train data contains target column 'IsBadBuy', therefore\n",
    "- First step is constract similar structure from features_train\n",
    "- Second step is to build prediction workflow \n",
    "- Third step is to check with feature_test the total workflow\n",
    "- Forth step is to make final prediction on aim data (test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1. constract similar structure from features_train\n",
    "train =  features_train.join(target_train, sort='index')\n",
    "test = features_test\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 2. constract prediction workflow \n",
    "\n",
    "cols_cat = ['Auction', 'VehicleAge', 'Make', 'Model', 'Trim', 'SubModel', 'WheelType', 'BYRNO', 'VNZIP1', # cols to use\n",
    "            'Nationality', 'IsOnlineSale', 'Transmission', 'Color', 'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'Size', 'VNST', 'VehYear', 'WheelTypeID'] # cols to drop\n",
    "\n",
    "cols_num = ['MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\n",
    "            'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "            'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "            'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', \n",
    "            'VehOdo', 'VehBCost', 'WarrantyCost']\n",
    "\n",
    "col_target = 'IsBadBuy'\n",
    "\n",
    "def basis_model_predict(train, test, cols_cat, cols_num, col_target):\n",
    "    \n",
    "    target = train['IsBadBuy'].to_numpy()\n",
    "    features_train = train.drop(columns=[col_target])\n",
    "    #features_test = test.sort_index()\n",
    "    features_test = test\n",
    "    ## preprocessing \n",
    "    prepare_pipe = PrepareColsBase(cols_cat=cols_cat, cols_num=cols_num, max_cat=25).make_pipe()\n",
    "    prepare_pipe.fit(features_train, target)\n",
    "    data_pipe_train = prepare_pipe.transform(features_train)\n",
    "    data_pipe_test = prepare_pipe.transform(features_test)\n",
    "\n",
    "    ## models\n",
    "    model_tree =  DecisionTreeClassifier(class_weight='balanced', random_state=42, max_depth=4)\n",
    "    model_forest = RandomForestClassifier(class_weight='balanced', random_state=42, max_depth=10)\n",
    "    model_logreg = LogisticRegression(class_weight='balanced', random_state=42, C=0.01)\n",
    "\n",
    "\n",
    "    model_tree.fit(data_pipe_train, target)\n",
    "    print('model tree fit')\n",
    "    model_forest.fit(data_pipe_train, target)\n",
    "    print('model forest fit')\n",
    "    model_logreg.fit(data_pipe_train, target)\n",
    "    print('model logistic regression fit')\n",
    "\n",
    "    pred_tree = pd.DataFrame(model_tree.predict(data_pipe_test), index=features_test.index)\n",
    "    pred_forest = pd.DataFrame(model_forest.predict(data_pipe_test), index=features_test.index)\n",
    "    pred_logreg = pd.DataFrame(model_logreg.predict(data_pipe_test), index=features_test.index)\n",
    "\n",
    "\n",
    "    result = unanimity([pred_tree, pred_forest, pred_logreg])\n",
    "    df_result = pd.DataFrame(result)\n",
    "    # print(df_result.columns)\n",
    "    df_result = df_result.rename(columns={'sum': col_target })\n",
    "    return df_result \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = basis_model_predict(train, test, cols_cat, cols_num, col_target)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 3. Check with feature_test the total workflow\n",
    "report = classification_report(target_test.sort_index(), result)\n",
    "print('result report: \\n', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 4. The final prediction on aim data\n",
    "\n",
    "data_train = pd.read_csv(path_absolute + '\\\\data\\\\DontGetKicked\\\\training.csv', \n",
    "                         parse_dates=['PurchDate'], \n",
    "                         index_col=0)\n",
    "data_train.loc[:, 'WheelTypeID'] = data_train['WheelTypeID'].astype(str)\n",
    "data_train.head()\n",
    "\n",
    "data_test = pd.read_csv(path_absolute + '\\\\data\\\\DontGetKicked\\\\test.csv', \n",
    "                         parse_dates=['PurchDate'], \n",
    "                         index_col=0)\n",
    "data_test.loc[:, 'WheelTypeID'] = data_test['WheelTypeID'].astype(str)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aim = basis_model_predict(data_train, data_test, cols_cat, cols_num, col_target)\n",
    "pred_aim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aim.to_csv(path_absolute + '\\\\data\\\\01_Basis_Model_prediction\\\\basis_model.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
